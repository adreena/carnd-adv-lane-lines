{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimage\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def image_display(image,title=''):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.title(title)\n",
    "    plt.imshow(image, cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "def side2side_plotter(images):\n",
    "    # Plot the result\n",
    "    number_of_plots = len(images)\n",
    "    if number_of_plots>1:\n",
    "        fig , (ax)= plt.subplots(1, number_of_plots, figsize=(10, 9))\n",
    "        fig.tight_layout()\n",
    "        for i in range(number_of_plots):\n",
    "            ax[i].imshow(images[i][0],cmap='Greys_r')\n",
    "            ax[i].set_title(images[i][1])\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    elif number_of_plots==1:\n",
    "        fig, ax= plt.subplots(1, 1, figsize=(5, 5)) \n",
    "        ax.imshow(images[0][0],cmap='Greys_r')\n",
    "        ax.set_title(images[0][1])\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 1- calibrating camera\n",
    "\n",
    "camera_images = glob.glob('camera_cal/*') \n",
    "print('Images available for calibrating camera: {}'.format(len(camera_images)))\n",
    "\n",
    "#calibration rows/cols\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "#creating images_points and object_points list for calibrating camera\n",
    "image_points = []\n",
    "object_points = []\n",
    "\n",
    "default_obj_point = np.zeros((ny*nx,3), np.float32)\n",
    "default_obj_point[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "print('Wroking ...')\n",
    "failed_corners = []\n",
    "success_corners = []\n",
    "for i , img in enumerate(camera_images):\n",
    "    #read image\n",
    "    im = mpimage.imread(img)\n",
    "    #gray scale\n",
    "    gray_im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #get corners\n",
    "    ret, corners =  cv2.findChessboardCorners(gray_im, (nx,ny))\n",
    "    if ret is True:\n",
    "        image_points.append(corners)\n",
    "        object_points.append(default_obj_point)\n",
    "        cv2.drawChessboardCorners(im, (nx,ny), corners, ret)\n",
    "        success_corners.append((im,img))\n",
    "    else:\n",
    "        failed_corners.append((i,img))\n",
    "print('Finished collecting points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Detected corners:')\n",
    "\n",
    "for i in range(0,len(success_corners),3):\n",
    "    display_images=[]\n",
    "    im1= success_corners[i][0]\n",
    "    display_images.append([im1,\"{}\".format(success_corners[i][1])])\n",
    "    if (i+1) < len(success_corners):\n",
    "        im2= success_corners[i+1][0]\n",
    "        display_images.append([im2,\"{}\".format(success_corners[i+1][1])])\n",
    "        if (i+2) < len(success_corners):\n",
    "            im3= success_corners[i+2][0]\n",
    "            display_images.append([im3,\"{}\".format(success_corners[i+2][1])])\n",
    "    side2side_plotter(display_images)\n",
    "    \n",
    "print('Failed on finding corners for the following images:')\n",
    "for i,im in failed_corners:\n",
    "    print('image #{}, path: {}'.format(i,im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# step 2\n",
    "def undistort(img):\n",
    "    img_copy = np.copy(img)\n",
    "    img_size=(img.shape[1],img_copy.shape[0])\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera( object_points, image_points, img_size,None,None)\n",
    "    undistort_image = cv2.undistort(img_copy, mtx, dist, None, mtx)\n",
    "    return undistort_image\n",
    "\n",
    "# testing calibrate and undistort on an image that was not used in \n",
    "img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "undistort_image = undistort(img)\n",
    "u_images = [[img,'original'], [undistort_image,'undistorted']]\n",
    "side2side_plotter(u_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Finding gradient binary\n",
    "def gradient_binary(img, thresh=[90,200],orientation='x', ksize=3):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    if orientation=='y':\n",
    "        sobel = cv2.Sobel(gray_img, cv2.CV_64F,0,1, ksize=ksize)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray_img, cv2.CV_64F,1,0, ksize=ksize)\n",
    "    sobel_abs = np.absolute(sobel)\n",
    "    sobel_scaled= np.uint8(255* sobel_abs/np.max(sobel_abs))\n",
    "    sobel_binary = np.zeros_like(sobel_scaled)\n",
    "    sobel_binary[(sobel_scaled>thresh[0])&(sobel_scaled<=thresh[1])]=1\n",
    "    return sobel_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# converting image to HLS channel\n",
    "\n",
    "def hls_binary(img, thresh=[90,200], channel='s'):\n",
    "    hls_img = cv2.cvtColor(img,cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    if channel =='h':\n",
    "        hls_img = hls_img[:,:,0]\n",
    "    elif channel == 'l':\n",
    "        hls_img = hls_img[:,:,1]\n",
    "    else:\n",
    "        hls_img = hls_img[:,:,2]\n",
    "    hls_binary= np.zeros_like(hls_img)\n",
    "    hls_binary[(hls_img>thresh[0])&(hls_img<=thresh[1])]=1\n",
    "    return hls_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rgb_binary(img, thresh=[90,200], channel='r'):\n",
    "    copy_img = np.copy(img)\n",
    "    if channel =='r':\n",
    "        copy_img = copy_img[:,:,0]\n",
    "    elif channel == 'g':\n",
    "        copy_img = copy_img[:,:,1]\n",
    "    else:\n",
    "        copy_img = copy_img[:,:,2]\n",
    "    rgb_binary= np.zeros_like(copy_img)\n",
    "    rgb_binary[(copy_img>thresh[0])&(copy_img<=thresh[1])]=1\n",
    "    return rgb_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#step 3\n",
    "def combine_binaries(binary_img1, binary_img2, return_color_combination=False):\n",
    "    color_combination=[]\n",
    "    if return_color_combination is True:\n",
    "        color_combination = np.dstack((np.zeros_like(binary_img1), binary_img1, binary_img2))\n",
    "    binary = np.zeros_like(binary_img1)\n",
    "    binary[(binary_img1==1)|(binary_img2==1)]=1\n",
    "    return binary, color_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#testing sobel & hls\n",
    "test_img = mpimage.imread('test_images/v1.jpg')\n",
    "undistort_image = undistort(test_img)\n",
    "# undistort_image= adjust_gamma(undistort_image, gamma=0.5)\n",
    "\n",
    "sobel_img = gradient_binary(undistort_image, thresh=[50,150])\n",
    "hls_img = hls_binary(undistort_image, thresh=[150,255])\n",
    "rgb_img = rgb_binary(undistort_image, thresh=[150,255])\n",
    "side2side_plotter([[test_img,'original'],[sobel_img,'sobel X'],[hls_img,'Channel S'],[rgb_img,'Channel R']])\n",
    "combined_binary, color_combination = combine_binaries(sobel_img, hls_img, True)\n",
    "combined_binary2, color_combination2 = combine_binaries(combined_binary, rgb_img, False)\n",
    "side2side_plotter([[color_combination,'Sobel X & Channel S'],[combined_binary,'HLS & Sobel Combined']])\n",
    "side2side_plotter([[combined_binary2,'HLS(S) & Sobel & RGB(R) Combined']])\n",
    "image_display(combined_binary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#step 4\n",
    "def get_perspective_transformation(img, src_vertices, dst_vertices):\n",
    "    src =np.float32(src_vertices)\n",
    "    dst=np.float32(dst_vertices)\n",
    "    M = cv2.getPerspectiveTransform(src,dst)\n",
    "    warped_image = cv2.warpPerspective(img, M, (img.shape[1],img.shape[0]))\n",
    "    return warped_image, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# region of interest\n",
    "def display_region(original_img , gray_img, src_vertices):\n",
    "    img_copy = np.copy(original_img)\n",
    "    pts = np.array(src_vertices, np.int32)\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    cv2.polylines(img_copy,[pts],True,(255,0,0), thickness=3)\n",
    "    return img_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test_img = mpimage.imread('test_images/test2.jpg')\n",
    "# img_size = [combined_binary.shape[0],combined_binary.shape[1]]\n",
    "# src_vertices =[[570,440],[650,440],[810,500],[520,500]]\n",
    "# offset = 200\n",
    "# dst_vertices = [[offset,offset],[img_size[1]-1,offset],[img_size[1]-1,img_size[0]-1],[offset,img_size[0]-1]]\n",
    "    \n",
    "# img_region = display_region(test_img,combined_binary,src_vertices)\n",
    "# warped_img, M = get_perspective_transformation(combined_binary,src_vertices,dst_vertices)\n",
    "# side2side_plotter([[img_region,'Region of Interest'],[warped_img,'Warped Image']])\n",
    "\n",
    "# test region & warp\n",
    "test_img = mpimage.imread('test_images/v1.jpg')\n",
    "img_size = [combined_binary.shape[0],combined_binary.shape[1]]\n",
    "# src_vertices =[[570,440],[690,440],[1200,700],[290,700]]\n",
    "src_vertices =[[510,480],[740,480],[1040,720],[160,720]]\n",
    "\n",
    "# src_vertices =[[520,500],[810,500],[1200,700],[290,700]]\n",
    "offset = 100\n",
    "dst_vertices = [[offset,offset],[img_size[1]-1,offset],[img_size[1]-1,img_size[0]-1],[offset,img_size[0]-1]]\n",
    "    \n",
    "img_region = display_region(test_img,combined_binary,src_vertices)\n",
    "warped_img, M = get_perspective_transformation(combined_binary,src_vertices,dst_vertices)\n",
    "side2side_plotter([[img_region,'Region of Interest'],[warped_img,'Warped Image']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# step 5\n",
    "# histogram | convolve\n",
    "\n",
    "def reject_outliers(datax,datay, m=2):\n",
    "    indicies= np.where(abs(datax - np.mean(datax)) < m * np.std(datax))[0]\n",
    "    outputx= datax[indicies]\n",
    "    outputy= datay[indicies]\n",
    "    return outputx,outputy\n",
    "\n",
    "def sliding_window_histogram(img, n_windows=9):\n",
    "    try:\n",
    "        good_left = []\n",
    "        good_right = []\n",
    "        img_output = np.dstack((img, img, img))*255\n",
    "        histogram = np.sum(img[int(img.shape[0]/2):,:], axis=0)\n",
    "\n",
    "        window_height = int(img.shape[0]/n_windows)\n",
    "        #find halves\n",
    "        midpoint= int(histogram.shape[0]/2)\n",
    "        left_half = histogram[0:midpoint]\n",
    "        right_half = histogram[midpoint:]\n",
    "\n",
    "        #find nonzeros\n",
    "        nonzero = img.nonzero()\n",
    "        nonzero_x = np.array(nonzero[1])\n",
    "        nonzero_y = np.array(nonzero[0])\n",
    "\n",
    "        #get the base\n",
    "        left_base = np.argmax(left_half, axis=0)\n",
    "        right_base = np.argmax(right_half, axis=0)+midpoint\n",
    "\n",
    "        left_current = left_base\n",
    "        right_current = right_base\n",
    "\n",
    "        max_pix = 300\n",
    "        number_nonzeros = 500\n",
    "        margin = 150\n",
    "        left_margin  =150\n",
    "        last_good_points_left = np.array([])\n",
    "        last_good_points_right = np.array([])\n",
    "        for i in range(n_windows):\n",
    "            \n",
    "            y_high = img.shape[0] - i*window_height\n",
    "            y_low = img.shape[0] - (i+1)*window_height\n",
    "\n",
    "            x_left_low = left_current-left_margin\n",
    "            x_left_high = left_current+margin\n",
    "\n",
    "            x_right_low = right_current-margin\n",
    "            x_right_high = right_current+margin\n",
    "\n",
    "            cv2.rectangle(img_output, (x_left_low, y_low) ,(x_left_high, y_high), (0,255,0),2)\n",
    "            cv2.rectangle(img_output, (x_right_low, y_low) ,(x_right_high, y_high), (0,255,0),2)\n",
    "\n",
    "            good_left_indexes = ((nonzero_x>x_left_low)&(nonzero_x<x_left_high)&(nonzero_y>y_low)&(nonzero_y<y_high)).nonzero()[0]\n",
    "            good_right_indexes = ((nonzero_x>x_right_low)&(nonzero_x<x_right_high)&(nonzero_y>y_low)&(nonzero_y<y_high)).nonzero()[0]\n",
    "\n",
    "            good_left.append(good_left_indexes)\n",
    "            good_right.append(good_right_indexes)\n",
    "            if len(good_left_indexes)>= max_pix :\n",
    "                left_current= np.int(np.mean(nonzero_x[good_left_indexes]))\n",
    "            if len(good_right_indexes)>= max_pix:\n",
    "                right_current= np.int(np.mean(nonzero_x[good_right_indexes]))\n",
    "\n",
    "\n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(good_left)\n",
    "        right_lane_inds = np.concatenate(good_right)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzero_x[left_lane_inds]\n",
    "        lefty = nonzero_y[left_lane_inds] \n",
    "        rightx = nonzero_x[right_lane_inds]\n",
    "        righty = nonzero_y[right_lane_inds] \n",
    "       \n",
    "        # Fit a second order polynomial to each\n",
    "\n",
    "        ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "        try:\n",
    "            leftx, lefty= reject_outliers(leftx,lefty)\n",
    "            left_fit = np.polyfit(lefty, leftx, 2)\n",
    "            left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        except Exception as err:\n",
    "            left_fitx=None\n",
    "            left_fit=None\n",
    "\n",
    "        try:\n",
    "            rightx, righty= reject_outliers(rightx,righty)\n",
    "            right_fit = np.polyfit(righty, rightx, 2)\n",
    "            right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        except Exception as err:\n",
    "            right_fitx = None\n",
    "            right_fit = None\n",
    "\n",
    "\n",
    "#         if right_fit is None or len(rightx) < number_nonzeros:\n",
    "#             if len(leftx)>number_nonzeros:\n",
    "#                 right_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2] + 2*int(img.shape[1]/3)-50\n",
    "#                 right_fit = np.array([left_fit[0], left_fit[1], left_fit[2] + 2*int(img.shape[1]/3)-50])\n",
    "#                 rightx = rightx + 2*int(img.shape[1]/3)\n",
    "#                 righty = righty\n",
    "\n",
    "\n",
    "#         if left_fit is None or len(leftx) < number_nonzeros:\n",
    "#             if len(rightx)>number_nonzeros:\n",
    "#                 left_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2] - 2*int(img.shape[1]/3)+50\n",
    "#                 left_fit = np.array([right_fit[0], right_fit[1], right_fit[2] - 2*int(img.shape[1]/3)+50])\n",
    "#                 leftx = rightx -2*int(img.shape[1]/3)\n",
    "#                 lefty = righty\n",
    "\n",
    "        img_output[nonzero_y[left_lane_inds], nonzero_x[left_lane_inds]] = [255, 0, 0]\n",
    "        img_output[nonzero_y[right_lane_inds], nonzero_x[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        left_line = {'x':leftx, 'y':lefty, 'fitx':left_fitx, 'coefficient':left_fit, 'slope':0}\n",
    "        right_line = {'x':rightx, 'y':righty, 'fitx':right_fitx, 'coefficient':right_fit, 'slope':0}\n",
    "\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "    return img_output, left_line, right_line, ploty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_img, left_line, right_line, ploty = sliding_window_histogram(warped_img)\n",
    "plt.imshow(output_img)\n",
    "if left_line['fitx'] is not None:\n",
    "    plt.plot(left_line['fitx'], ploty, color='yellow')\n",
    "if right_line['fitx'] is not None:\n",
    "    plt.plot(right_line['fitx'], ploty, color='yellow')\n",
    "plt.xlim(0, warped_img.shape[1])\n",
    "plt.ylim(warped_img.shape[0], 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calculate_curve_slope_distance(warped_img, lines, ploty):\n",
    "    lines['left']['curve']= 0\n",
    "    lines['right']['curve']= 0\n",
    "    car_position = (warped_img.shape[1]/2)\n",
    "    ym_per_pix = 30/warped_img.shape[0]# meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/warped_img.shape[1]/2 # meters per pixel in x dimension\n",
    "    meter_per_pixel={'x':xm_per_pix,'y':ym_per_pix}\n",
    "    \n",
    "    try:\n",
    "        center_x_point= int(warped_img.shape[1]/2)\n",
    "        y_eval = np.max(ploty)\n",
    "        # Fit new polynomials to x,y in world space\n",
    "        fit_cr_left = np.polyfit(lines['left']['y']*ym_per_pix, lines['left']['x']*xm_per_pix, 2)\n",
    "        fit_cr_right = np.polyfit(lines['right']['y']*ym_per_pix, lines['right']['x']*xm_per_pix, 2)\n",
    "\n",
    "        # Calculate the new radii of curvature\n",
    "        curve_left = ((1 + (2*fit_cr_left[0]*y_eval*ym_per_pix + fit_cr_left[1])**2)**1.5) / np.absolute(2*fit_cr_left[0])\n",
    "        curve_right = ((1 + (2*fit_cr_right[0]*y_eval*ym_per_pix + fit_cr_right[1])**2)**1.5) / np.absolute(2*fit_cr_right[0])\n",
    "        lines['left']['curve']= curve_left\n",
    "        lines['right']['curve']= curve_right\n",
    "        center_of_image = int(warped_img.shape[1]/2)\n",
    "        car_position = (((lines['right']['x'][0]+ lines['left']['x'][0])/2) -center_of_image) * xm_per_pix\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        pass\n",
    "    finally:\n",
    "        lines['distance'] = car_position\n",
    "    return lines,meter_per_pixel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create an image to draw the lines on\n",
    "import math\n",
    "\n",
    "flags = {'slope':False, 'distance':False, 'expected':False, 'curve':False}\n",
    "def project_lines_to_road(img_resources, lines, meter_per_pixel, M):\n",
    "    \n",
    "    original_img = img_resources['original']\n",
    "    warped_img = img_resources['warped']\n",
    "    undistort_img = img_resources['undistorted']\n",
    "    left_line = lines['left']\n",
    "    right_line = lines['right']\n",
    "    ploty = lines['ploty']\n",
    "    curve= (lines['left']['curve'] + lines['right']['curve'])/2\n",
    "    car_position = lines['distance']\n",
    "    \n",
    "    warp_zero = np.zeros_like(warped_img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_line['fitx'], ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_line['fitx'], ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255,0))\n",
    "    \n",
    "    Minv = np.linalg.inv(M)\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (original_img.shape[1], original_img.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undistort_img, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    cv2.putText(result,'curve_avg: {0:.2f}m'.format(curve),(850,50), font, 1,(255,255,255),2)\n",
    "    \n",
    "    cv2.putText(result,'distance_center: {0:.2f}m '.format(car_position),(850,100), font, 1,(255,255,255),2)\n",
    "    \n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#test \n",
    "image_res = {'original':test_img,'warped':warped_img,'undistorted':undistort_image}\n",
    "lines= {'left':left_line,'right':right_line, 'ploty':ploty}\n",
    "lines,meter_per_pixel = calculate_curve_slope_distance(warped_img, lines, ploty)\n",
    "output_img = project_lines_to_road(image_res, lines, meter_per_pixel,M)\n",
    "image_display(output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #avg distance\n",
    "        self.avg_pos = None\n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        self.coefficients = None\n",
    "        self.line =None\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "  \n",
    "    \n",
    "    def get_avg_coefficients(self,all_instances):\n",
    "        count =1\n",
    "        coefficients = all_instances[-1].coefficients\n",
    "        if len(all_instances) >1:\n",
    "            coefficients += all_instances[-2].coefficients\n",
    "            count+=1\n",
    "            if len(all_instances) >2:\n",
    "                coefficients += all_instances[-3].coefficients\n",
    "                count+=1\n",
    "        avg_coefficients = (coefficients+self.coefficients)/(count+1)\n",
    "        return avg_coefficients\n",
    "    \n",
    "    \n",
    "    def populate(self,new_line,all_instances,meter_per_pixel):\n",
    "        try:\n",
    "            if new_line['fitx'] is not None and new_line['coefficient'] is not None:\n",
    "                self.detected = True \n",
    "    #             self.current_fit = new_line['coefficient']\n",
    "                self.current_fit = new_line['coefficient']\n",
    "                self.radius_of_curvature = new_line['curve']\n",
    "                self.line_base_pos = new_line['x'][0]*meter_per_pixel['x']\n",
    "                self.allx = new_line['x']\n",
    "                self.ally = new_line['y']\n",
    "\n",
    "                if len(all_instances) > 0:\n",
    "                    self.diffs = all_instances[-1].current_fit - self.current_fit\n",
    "                    self.recent_xfitted = all_instances[-1].allx\n",
    "                    self.bestx = (new_line['fitx']+all_instances[-1].bestx*len(all_instances))/(len(all_instances)+1)\n",
    "                    self.best_fit = self.current_fit\n",
    "                else:\n",
    "                    self.recent_xfitted = new_line['fitx']\n",
    "                    self.bestx =  new_line['fitx']\n",
    "                    self.best_fit = new_line['coefficient']\n",
    "                    self.diffs = None\n",
    "                    self.current_fit = new_line['coefficient']\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# def find_slope(coefficients, height):\n",
    "#     y_top = 0\n",
    "#     y_bottom = height\n",
    "#     x_top = coefficients[0]*y_top**2 + coefficients[1]*y_top +  coefficients[2]\n",
    "#     x_bottom = coefficients[0]*y_bottom**2 + coefficients[1]*y_bottom +  coefficients[2]\n",
    "#     m = (y_bottom - y_top)/(x_bottom-x_top)\n",
    "#     return m\n",
    "\n",
    "\n",
    "def get_avg_coefficients(all_instances):\n",
    "        count =1\n",
    "        coefficients = all_instances[-1].current_fit\n",
    "        if len(all_instances) >3:\n",
    "            coefficients = (all_instances[-1].current_fit+all_instances[-2].current_fit+all_instances[-3].current_fit)/3\n",
    "        elif len(all_instances) >2:\n",
    "            coefficients = (all_instances[-1].current_fit+all_instances[-2].current_fit)/2\n",
    "        \n",
    "        return coefficients\n",
    "    \n",
    "def find_slope(coefficients, height):\n",
    "    y_mid = height/2\n",
    "    slope = 2*coefficients[0]*y_mid + coefficients[1]*y_mid\n",
    "    return slope\n",
    "    \n",
    "    \n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)    \n",
    "\n",
    "def evaluate(warped_img,combined_binary,dst_vertices,new_lines, new_instances,all_instances , distance_offset_meter = 0.5, slope_offset=2, curve_offset =1000):\n",
    "    flags = {'slope':False, 'distance':False, 'expected':False, 'curve':False, 'fixed':False, 'slope_left':0, 'x_right':0, 'x_left':0,'slope_right':0, 'fixed':False, 'right':'', 'left':''}\n",
    "    global count_bad_frames \n",
    "#     global old_white_ratio\n",
    "    global white_ratio_increasing\n",
    "    ploty = np.linspace(0, warped_img.shape[0]-1, warped_img.shape[0] )\n",
    "    slope1=0.0\n",
    "    slope2=0.0\n",
    "    d1 = 0.0\n",
    "    d2= 0.0\n",
    "    right_needs_fix = False\n",
    "    left_needs_fix = False\n",
    "    try:\n",
    "        good_match = False\n",
    "        \n",
    "        upper_src_vertices =[[570,440],[650,440],[810,500],[520,500]]\n",
    "        img_size = [combined_binary.shape[0],combined_binary.shape[1]]       \n",
    "        warped_img_upper, M = get_perspective_transformation(combined_binary,upper_src_vertices,dst_vertices)\n",
    "        output_img_upper, left_line_upper, right_line_upper, _ = sliding_window_histogram(warped_img_upper)\n",
    "#         plt.imshow(output_img_upper)\n",
    "#         if left_line_upper['fitx'] is not None:\n",
    "#             plt.plot(left_line_upper['fitx'], ploty, color='yellow')\n",
    "#         if right_line_upper['fitx'] is not None:\n",
    "#             plt.plot(right_line_upper['fitx'], ploty, color='yellow')\n",
    "#         plt.xlim(0, warped_img_upper.shape[1])\n",
    "#         plt.ylim(warped_img_upper.shape[0], 0)\n",
    "#         plt.show()\n",
    "        \n",
    "        total_pix1 = warped_img.shape[0]*warped_img.shape[1]\n",
    "        total_white1 = cv2.countNonZero(warped_img)\n",
    "        white_ratio1 = int((total_white1/total_pix1)*100)\n",
    "        \n",
    "        top_of_img = np.copy(warped_img_upper)\n",
    "        total_pix = top_of_img.shape[0]*top_of_img.shape[1]\n",
    "        total_white = cv2.countNonZero(top_of_img)\n",
    "   \n",
    "        y_mid = int(warped_img.shape[0]/2)\n",
    "\n",
    "        #check distance, slope and curve\n",
    "        if len(all_instances['left']) >0 and len(all_instances['right'])>0 :\n",
    "            \n",
    "            '''\n",
    "            1- is line detected?\n",
    "            '''\n",
    "            if new_instances['left'].detected is True and new_instances['right'].detected is True:\n",
    "                good_match = True\n",
    "                \n",
    "            '''\n",
    "            2- check expected x value\n",
    "            find indices of the top of the image [0,~300] for left & right\n",
    "            calculate the mean position of x,y for left and right\n",
    "            calculate expected x value for such y using previous left_fitx & right_fitx \n",
    "            '''\n",
    "            half_img = int(warped_img.shape[0]/2)\n",
    "            indices_left =np.where(new_lines['left']['y']<=half_img )            \n",
    "            current_y_left = np.mean(new_lines['left']['y'][indices_left])\n",
    "            current_x_left = np.mean(new_lines['left']['x'][indices_left])\n",
    "\n",
    "            expected_x_left = all_instances['left'][-1].current_fit[0]* current_y_left**2 \\\n",
    "                            + all_instances['left'][-1].current_fit[1]*current_y_left + all_instances['left'][-1].current_fit[2]\n",
    "            \n",
    "            indices_right =np.where(new_lines['right']['y']<=half_img )            \n",
    "            current_y_right = np.mean(new_lines['right']['y'][indices_right])\n",
    "            current_x_right = np.mean(new_lines['right']['x'][indices_right])\n",
    "\n",
    "            expected_x_right = all_instances['right'][-1].current_fit[0]* current_y_right**2 \\\n",
    "                            + all_instances['right'][-1].current_fit[1]*current_y_right + all_instances['right'][-1].current_fit[2]\n",
    "             \n",
    "            '''\n",
    "            3- check expected slope value\n",
    "            find slope of left & right fit using 1st derivatives of current left, right fits\n",
    "            find slope of left & right fit using 1st derivatives of previous fit\n",
    "            '''\n",
    "            current_left_slope = find_slope(new_instances['left'].current_fit, warped_img.shape[0])\n",
    "            expected_left_slope= find_slope(all_instances['left'][0].current_fit, warped_img.shape[0])\n",
    "            current_right_slope = find_slope(new_instances['right'].current_fit, warped_img.shape[0])\n",
    "            expected_right_slope = find_slope(all_instances['right'][0].current_fit, warped_img.shape[0])\n",
    "            \n",
    "\n",
    "            '''\n",
    "            4- check expected Vs current values for both left and right and set theri flags\n",
    "            '''\n",
    "            if abs(expected_left_slope - current_left_slope)>10 or abs(expected_x_left - current_x_left)>15 :\n",
    "                good_match =False\n",
    "                left_needs_fix = True\n",
    "        \n",
    "            if abs(expected_right_slope - current_right_slope)>10 or abs(expected_x_right - current_x_right)>15 :\n",
    "                good_match =False\n",
    "                right_needs_fix = True\n",
    "                             \n",
    "        '''\n",
    "        First entry, empty cache\n",
    "        '''\n",
    "        else:\n",
    "            if new_instances['left'].detected is True and new_instances['right'].detected is True:\n",
    "                good_match = True\n",
    "                \n",
    "        '''\n",
    "        check cached lines\n",
    "        '''\n",
    "        if len(all_instances['left']) >0 and len(all_instances['right']) >0:\n",
    "            '''\n",
    "            if its not a good match do left or right fix by copying previous instances from the cache\n",
    "            and increment count_bad_frames\n",
    "            '''\n",
    "            if good_match is False:\n",
    "                if left_needs_fix is True:\n",
    "                    new_instances['left']= all_instances['left'][-1]\n",
    "                    new_lines['left']['fitx'] = all_instances['left'][-1].current_fit[0]*ploty**2 + all_instances['left'][-1].current_fit[1]*ploty + all_instances['left'][-1].current_fit[2]\n",
    "                    new_lines['left']['x'] = all_instances['left'][-1].allx\n",
    "                    new_lines['left']['y'] = all_instances['left'][-1].ally\n",
    "                    new_lines['left']['coefficients'] =  all_instances['right'][-1].current_fit\n",
    "                    flags['left']='fixed'\n",
    "\n",
    "                if right_needs_fix is True:\n",
    "                    new_instances['right']= all_instances['right'][-1]\n",
    "                    new_lines['right']['fitx'] = all_instances['right'][-1].current_fit[0]*ploty**2 + all_instances['right'][-1].current_fit[1]*ploty + all_instances['right'][-1].current_fit[2]\n",
    "                    new_lines['right']['x'] = all_instances['right'][-1].allx\n",
    "                    new_lines['right']['y'] = all_instances['right'][-1].ally\n",
    "                    new_lines['right']['coefficients'] =  all_instances['right'][-1].current_fit\n",
    "                    flags['right']='fixed'\n",
    "\n",
    "                count_bad_frames +=1\n",
    "                flags['fixed'] = True\n",
    "            else:\n",
    "                '''\n",
    "                reset counter, this frame is good !\n",
    "                '''\n",
    "                count_bad_frames =0\n",
    "        else:\n",
    "            '''\n",
    "            reset counter, this frame is good !\n",
    "            '''\n",
    "            count_bad_frames =0\n",
    "        '''\n",
    "        append frame to cached instance\n",
    "        '''\n",
    "        all_instances['left'].append(new_instances['left'])\n",
    "        all_instances['right'].append(new_instances['right'])\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        pass\n",
    "    return all_instances, new_lines, flags, count_bad_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # Import everything needed to edit/save/watch video clips\n",
    "# from moviepy.editor import VideoFileClip\n",
    "# from IPython.display import HTML\n",
    "\n",
    "# def normalized(img):\n",
    "#     norm_rgb=np.zeros((img.shape[0],img.shape[1],3),np.uint8)\n",
    "#     normal_img = np.copy(img)\n",
    "#     b=normal_img[:,:,0]\n",
    "#     g=normal_img[:,:,1]\n",
    "#     r=normal_img[:,:,2]\n",
    "\n",
    "#     sum=b+g+r\n",
    "\n",
    "#     normal_img[:,:,0]=b/sum*255.0\n",
    "#     normal_img[:,:,1]=g/sum*255.0\n",
    "#     normal_img[:,:,2]=r/sum*255.0\n",
    "\n",
    "#     norm_rgb=cv2.convertScaleAbs(normal_img)\n",
    "#     return norm_rgb\n",
    "\n",
    "# def process_image(image):\n",
    "#     global all_instances\n",
    "#     global src_vertices\n",
    "#     global offset\n",
    "#     global count_bad_frames\n",
    "#     global fram_counter\n",
    "#     global old_white_ratio\n",
    "#     global white_ratio_increasing\n",
    "#     output_image= np.copy(image)\n",
    "    \n",
    "#     undistort_img = undistort(image)\n",
    "#     undistort_img = adjust_gamma(undistort_img, gamma=0.5)\n",
    "#     image_display(undistort_img)\n",
    "#     sobel_img = gradient_binary(undistort_img, thresh=[50,150])\n",
    "#     hls_img = hls_binary(undistort_img, thresh=[100,255])\n",
    "    \n",
    "#     rgb_img = rgb_binary(undistort_img, thresh=[150,255])\n",
    "\n",
    "#     combined_binary1, color_combination = combine_binaries(sobel_img, hls_img, True)\n",
    "#     combined_binary, color_combination = combine_binaries(combined_binary1, rgb_img, True)\n",
    "\n",
    "#     image_display(combined_binary)\n",
    "#     img_size = [combined_binary.shape[0],combined_binary.shape[1]]       \n",
    "    \n",
    "#     dst_vertices = [[offset,offset],[img_size[1]-offset,offset],[img_size[1]-offset,img_size[0]-offset],[offset,img_size[0]-offset]]\n",
    "#     img_region = display_region(image,combined_binary,src_vertices)\n",
    "\n",
    "    \n",
    "# #     upper_src_vertices =[[570,440],[650,440],[810,500],[520,500]]\n",
    "#     img_size = [combined_binary.shape[0],combined_binary.shape[1]]       \n",
    "#     warped_img_upper, M = get_perspective_transformation(combined_binary,src_vertices,dst_vertices)\n",
    "#     output_img_upper, left_line_upper, right_line_upper, _ = sliding_window_histogram(warped_img_upper)\n",
    "# #        \n",
    "\n",
    "#     top_of_img = np.copy(warped_img_upper)\n",
    "#     total_pix = top_of_img.shape[0]*top_of_img.shape[1]\n",
    "#     total_white = cv2.countNonZero(top_of_img)\n",
    "#     white_ratio = int((total_white/total_pix)*100)\n",
    "    \n",
    "#     output_img = np.copy(undistort_img)\n",
    "# #     image_display(undistort_img, 'before')\n",
    "\n",
    "#     if old_white_ratio < white_ratio:\n",
    "#         white_ratio_increasing = True\n",
    "#         old_white_ratio = white_ratio\n",
    "#     else:\n",
    "#         white_ratio_increasing = False\n",
    "#         old_white_ratio = white_ratio\n",
    "        \n",
    "# #     if white_ratio>4:\n",
    "# # #         image_display(undistort_img, 'before')\n",
    "# # #         normal_img = normalized(undistort_img)\n",
    "# # #         image_display(normal_img, 'normalized')\n",
    "# #         gamma_fix = adjust_gamma(undistort_img, gamma=1.5)\n",
    "# # #         image_display(gamma_fix)\n",
    "# #         sobel_img = gradient_binary(gamma_fix, thresh=[50,150])\n",
    "# #         hls_img = hls_binary(gamma_fix, thresh=[100,255])\n",
    "# #         combined_binary, color_combination = combine_binaries(sobel_img, hls_img, True)\n",
    "# # #         image_display(combined_binary)\n",
    "    \n",
    "\n",
    "#     warped_img, M = get_perspective_transformation(combined_binary,src_vertices,dst_vertices)\n",
    "\n",
    "#     output_img, left_line, right_line, ploty = sliding_window_histogram(warped_img)\n",
    "#     new_lines = {'left':left_line, 'right':right_line, 'ploty':ploty}\n",
    "    \n",
    "    \n",
    "    \n",
    "#     new_lines, meter_per_pixel = calculate_curve_slope_distance(warped_img, new_lines, ploty)\n",
    "#     image_resources = {'original':image, 'warped':warped_img, 'undistorted':undistort_img}\n",
    "#     left_instance = Line()\n",
    "#     left_instance.populate(new_lines['left'],all_instances['left'], meter_per_pixel) \n",
    "#     right_instance = Line()\n",
    "#     right_instance.populate(new_lines['right'],all_instances['right'], meter_per_pixel) \n",
    "#     new_instances = {'left': left_instance, 'right':right_instance}\n",
    "    \n",
    "#     all_instances,new_lines, flags, count_bad_frames = evaluate(warped_img,combined_binary,dst_vertices, new_lines, new_instances, all_instances)\n",
    "\n",
    "# #     plt.imshow(output_img)\n",
    "# #     if left_line['fitx'] is not None:\n",
    "# #         plt.plot(left_line['fitx'], ploty, color='yellow')\n",
    "# #     if right_line['fitx'] is not None:\n",
    "# #         plt.plot(right_line['fitx'], ploty, color='yellow')\n",
    "# #     plt.xlim(0, warped_img.shape[1])\n",
    "# #     plt.ylim(warped_img.shape[0], 0)\n",
    "# #     plt.show()\n",
    "#     output_image = project_lines_to_road(image_resources,new_lines , meter_per_pixel,M)\n",
    "#     font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "\n",
    "# #     cv2.putText(output_image,'distance : {}'.format(flags['distance']),(850,200), font, 1,(255,255,255),2)\n",
    "# #     cv2.putText(output_image,'expected : {}'.format(flags['expected']),(850,250), font, 1,(255,255,255),2)\n",
    "# #     cv2.putText(output_image,'curve : {}'.format(flags['curve']),(850,300), font, 1,(255,255,255),2)\n",
    "# #     cv2.putText(output_image,'count : {}'.format(count_bad_frames),(850,350), font, 1,(255,255,255),2)\n",
    "#     cv2.putText(output_image,'slope_left : {}'.format(flags['slope_left']),(850,200), font, 1,(255,255,255),2)\n",
    "#     cv2.putText(output_image,'slope_right : {}'.format(flags['slope_right']),(850,250), font, 1,(255,255,255),2)\n",
    "#     cv2.putText(output_image,'x_left : {}'.format(flags['x_left']),(850,300), font, 1,(255,255,255),2)\n",
    "#     cv2.putText(output_image,'x_right : {}'.format(flags['x_right']),(850,350), font, 1,(255,255,255),2)\n",
    "#     cv2.putText(output_image,'bad_frame : {}'.format(count_bad_frames),(850,400), font, 1,(255,255,255),2)\n",
    "#     cv2.putText(output_image,'white_ratio : {}'.format(white_ratio),(850,450), font, 1,(255,255,255),2)\n",
    "#     cv2.putText(output_image,'left : {}'.format(flags['left']),(850,500), font, 1,(255,255,255),2)\n",
    "#     cv2.putText(output_image,'right : {}'.format(flags['right']),(850,550), font, 1,(255,255,255),2)\n",
    "#     cv2.putText(output_image,'white_ratio_increasing : {}'.format(white_ratio_increasing),(850,600), font, 1,(255,255,255),2)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# #     fram_counter+=1\n",
    "#     image_display(output_image)\n",
    "# #     #reset\n",
    "#     if white_ratio_increasing is False and white_ratio<6 and count_bad_frames>3:\n",
    "#         all_instances = {'left':[],'right':[]}\n",
    "#         count_bad_frames = 0\n",
    "#     return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def process_image(image):\n",
    "    global all_instances\n",
    "    global src_vertices\n",
    "    global offset\n",
    "    global count_bad_frames\n",
    "    global old_white_ratio\n",
    "    global white_ratio_increasing\n",
    "    global make_darker\n",
    "    global rgb_channel\n",
    "    global make_brighter\n",
    "    global bad_frame_limit\n",
    "    \n",
    "    output_image= np.copy(image)\n",
    "    image_display(image,'original')\n",
    "\n",
    "    '''\n",
    "    Undistort the image\n",
    "    '''\n",
    "    undistort_img = undistort(image)\n",
    "    image_display(undistort_img, 'undistorted')\n",
    "    \n",
    "    img_size = [undistort_img.shape[0],undistort_img.shape[1]]  \n",
    "    \n",
    "    '''\n",
    "    if need to make image darker, apply gamma_correction 0.5 to change illumination\n",
    "    ''' \n",
    "    if make_darker:\n",
    "        undistort_img = adjust_gamma(undistort_img, gamma=0.5)\n",
    "        \n",
    "    '''\n",
    "    Combining binary color channels and sobel x\n",
    "    '''\n",
    "    sobel_img = gradient_binary(undistort_img, thresh=[50,150])\n",
    "    hls_img = hls_binary(undistort_img, thresh=[100,255])\n",
    "    combined_binary, color_combination = combine_binaries(sobel_img, hls_img, True)\n",
    "\n",
    "    '''\n",
    "    if need combining with rgb channel\n",
    "    '''\n",
    "    if rgb_channel:\n",
    "        rgb_img = rgb_binary(undistort_img, thresh=[150,255])\n",
    "        combined_binary, color_combination = combine_binaries(combined_binary, rgb_img, True)\n",
    "\n",
    "    image_display(combined_binary)\n",
    "         \n",
    "    \n",
    "    dst_vertices = [[offset,offset],[img_size[1]-offset,offset],[img_size[1]-offset,img_size[0]-offset],[offset,img_size[0]-offset]]\n",
    "    img_region = display_region(image,combined_binary,src_vertices)\n",
    "    \n",
    "    img_size = [combined_binary.shape[0],combined_binary.shape[1]]       \n",
    "\n",
    "    \n",
    "    '''\n",
    "    calculating white ratio in binary combination. \n",
    "    For average to perfect frames (no illumination or shadow) white ratio remains in 3-4% range\n",
    "    '''\n",
    "    total_pix = img_size[0]*img_size[1]\n",
    "    total_white = cv2.countNonZero(combined_binary)\n",
    "    white_ratio = int((total_white/total_pix)*100)\n",
    "    \n",
    "    '''\n",
    "    is white range increasing? I use it to look for upcoming very bright areas with high illumination \n",
    "    '''\n",
    "    if old_white_ratio < white_ratio:\n",
    "        white_ratio_increasing = True\n",
    "        old_white_ratio = white_ratio\n",
    "    else:\n",
    "        white_ratio_increasing = False\n",
    "        old_white_ratio = white_ratio\n",
    "        \n",
    "    '''\n",
    "    if need to make image brighter to detect light pavement illumination:\n",
    "    apply gamma_correction 1.5 & look for white ratio higher than 4 \n",
    "    ''' \n",
    "    if white_ratio>4 and make_brighter:\n",
    "        gamma_fix = adjust_gamma(undistort_img, gamma=1.5)\n",
    "        image_display(gamma_fix, 'Gamma Fix')\n",
    "        sobel_img = gradient_binary(gamma_fix, thresh=[50,150])\n",
    "        hls_img = hls_binary(gamma_fix, thresh=[100,255])\n",
    "        combined_binary, color_combination = combine_binaries(sobel_img, hls_img, True)\n",
    "        image_display(combined_binary, 'After Gamma Fix')\n",
    "    \n",
    "    '''\n",
    "    warp perspective transformation\n",
    "    ''' \n",
    "    warped_img, M = get_perspective_transformation(combined_binary,src_vertices,dst_vertices)\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Collect left & right pixels to draw polyfit with histogram and sliding windows\n",
    "    '''\n",
    "    _, left_line, right_line, ploty = sliding_window_histogram(warped_img)\n",
    "    new_lines = {'left':left_line, 'right':right_line, 'ploty':ploty}\n",
    "\n",
    "    '''\n",
    "    claculate curves and slope\n",
    "    '''\n",
    "    new_lines, meter_per_pixel = calculate_curve_slope_distance(warped_img, new_lines, ploty)\n",
    "    image_resources = {'original':image, 'warped':warped_img, 'undistorted':undistort_img}\n",
    "    \n",
    "    '''\n",
    "    Create Left & Right Line instances\n",
    "    '''\n",
    "    left_instance = Line()\n",
    "    left_instance.populate(new_lines['left'],all_instances['left'], meter_per_pixel) \n",
    "    right_instance = Line()\n",
    "    right_instance.populate(new_lines['right'],all_instances['right'], meter_per_pixel) \n",
    "    new_instances = {'left': left_instance, 'right':right_instance}\n",
    "    \n",
    "    '''\n",
    "    Evaluate the new frame (image)\n",
    "    '''\n",
    "    all_instances,new_lines, flags, count_bad_frames = evaluate(warped_img,combined_binary,dst_vertices, new_lines, new_instances, all_instances)\n",
    "\n",
    "    plt.imshow(output_img)\n",
    "    if left_line['fitx'] is not None:\n",
    "        plt.plot(left_line['fitx'], ploty, color='yellow')\n",
    "    if right_line['fitx'] is not None:\n",
    "        plt.plot(right_line['fitx'], ploty, color='yellow')\n",
    "    plt.xlim(0, warped_img.shape[1])\n",
    "    plt.ylim(warped_img.shape[0], 0)\n",
    "    plt.show()\n",
    "\n",
    "    '''project the lines onto the image'''\n",
    "    output_image = project_lines_to_road(image_resources,new_lines , meter_per_pixel,M)\n",
    "\n",
    "    '''\n",
    "    if white ratio is decreasing; meaning that bad frames are passing\n",
    "    reset the cache and do a fresh start for upcoming frames\n",
    "    '''\n",
    "    if white_ratio_increasing is False and white_ratio<6 and count_bad_frames>bad_frame_limit:\n",
    "        all_instances = {'left':[],'right':[]}\n",
    "        count_bad_frames = 0\n",
    "    image_display(output_img, 'Output')\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_instances = {'left':[],'right':[]}\n",
    "count_bad_frames = 0\n",
    "src_vertices =[[560,460],[750,460],[1200,700],[200,700]]\n",
    "offset = 100 \n",
    "fram_counter = 1\n",
    "old_white_ratio = 0\n",
    "white_ratio_increasing = False\n",
    "bad_frame_limit = 3\n",
    "make_darker = False\n",
    "rgb_channel = False\n",
    "make_brighter = True\n",
    "video_output = 'project_output.mp4'\n",
    "clip = VideoFileClip('project_video.mp4')\n",
    "# sub_clip = clip.subclip('00:00:30','00:00:45')\n",
    "project_clip = clip.fl_image(process_image)\n",
    "%time project_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def save_im(im):\n",
    "    im = Image.fromarray(im)\n",
    "#     im.save('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_instances = {'left':[],'right':[]}\n",
    "count_bad_frames = 0\n",
    "src_vertices =[[550,480],[750,480],[1200,720],[200,720]]\n",
    "offset = 100 \n",
    "fram_counter = 1\n",
    "old_white_ratio = 0\n",
    "white_ratio_increasing = False\n",
    "bad_frame_limit = 3\n",
    "make_darker = True\n",
    "rgb_channel = True\n",
    "make_brighter = False\n",
    "challenge_output = 'challenge_output.mp4'\n",
    "clip = VideoFileClip('challenge_video.mp4')\n",
    "challenge_clip = clip.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_instances = {'left':[],'right':[]}\n",
    "count_bad_frames = 0\n",
    "src_vertices =src_vertices =[[510,480],[740,480],[1040,720],[160,720]]\n",
    "offset = 100 \n",
    "fram_counter = 1\n",
    "old_white_ratio = 0\n",
    "harder_challenge_output = 'harder_challenge_output.mp4'\n",
    "clip = VideoFileClip('harder_challenge_video.mp4')\n",
    "harder_challenge_clip = clip.fl_image(process_image)\n",
    "%time harder_challenge_clip.write_videofile(harder_challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(harder_challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
